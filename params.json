{"name":"Tradeintel","tagline":"A repository of some of the code written for the startup, TradeIntel. ","body":"### Welcome to the TradeIntel demonstration repository!\r\nFeel free to jump straight into viewing the code or read below for a bit of background & guidance. This repository is a small selection of the code written for TradeIntel - enough to show my coding background to potential employers / peers, but without having the codebase open source.  \r\n\r\n## Background\r\nTradeIntel was a startup that Kevin Doran, myself, and later Finn Lawrence worked on for ~3 years. TradeIntel won several awards, was selected and participated in a startup accelerator, and most importantly began to show promising customer usage. However, due to legal/business reasons rather than technical reasons, we decided to move on from TradeIntel in 2014.\r\n\r\n## Technical overview\r\nTradeIntel was a SaaS product built entirely using Java EE 6/7 entirely by Kevin Doran and msyelf. At a very high level it had two parts: \r\n* Part A obtained data from a third party using an API, then stored this data using Percona Server in a ~50GB database. Besides communicating in a resilient, RESTful, and rate-limited manner, this part was also responsible for reliable XML-->Java-->MySQL storage, background database hot replication, automatic class generation using Jaxb, and version controlled database migration using Flyway. \r\n* Part B exposed this large amount of complex data to (authenticated) website users in a simple and explanatory way, using techniques that were scalable. \r\n\r\n## Technical Examples\r\nBelow are a selection of code segments with corresponding explanations. \r\n\r\n\r\n### Concurrent, resilient aggregation, and persistence of auction listings\r\n[This singleton](https://github.com/tgrunshaw/tradeintel/blob/master/tradeintel_listingretriever/tradeintel_listingretriever_ejb/src/main/java/nz/co/tradeintel/listingretriever/databaseupdater/ListingDetailUpdaterBean.java) is responsible for delegating auctions to [this message bean](https://github.com/tgrunshaw/tradeintel/blob/master/tradeintel_listingretriever/tradeintel_listingretriever_ejb/src/main/java/nz/co/tradeintel/listingretriever/databaseupdater/ListingDetailUpdaterMessageBean.java) (using JMS) which in turns uses the API caller functionality to request auction XML, parse to java, and persist in the database. A pool size of 20 message driven beans were used to concurrently do this, allowing us to overcome the network latency which would have otherwise caused the process to be too slow.  \r\n\r\n### Concurrent and encapsulated selection of API tokens from database \r\n[This class](https://github.com/tgrunshaw/tradeintel/blob/master/tradeintel_listingretriever/tradeintel_apicredentials_ejb/src/main/java/nz/co/tradeintel/trademe/TradeMeApiCallerBean.java) using [this class](https://github.com/tgrunshaw/tradeintel/blob/master/tradeintel_listingretriever/tradeintel_apicredentials_ejb/src/main/java/nz/co/tradeintel/trademe/oauth/TradeMeApiCredentialsConcurrentBean.java) (local interface [here](https://github.com/tgrunshaw/tradeintel/blob/master/tradeintel_listingretriever/tradeintel_apicredentials_ejb/src/main/java/nz/co/tradeintel/trademe/oauth/TradeMeApiCredentialsConcurrentBeanLocal.java)) provides a thread-safe mechanism to make API requests using a specific set of tokens, without ever using a token more than allowed (tokens are rate-limited per hour with a penalty for overuse). \r\n\r\n### API request functionality\r\n![](http://googledrive.com/host/0B8QP06llzL19SVoyb2dZTkJLTW8/2000px-ApiRequestArchitecture.png)\r\n\r\n\r\n### Python scripts & java reflection\r\nWe wanted to automate the generation of java classes from the provided XML schema (on every mvn package command) so we used a python script for this [?????]. We only wanted the java classes we use (there were 1000's otherwise), to find used classes I wrote a (probably over complicated) class that cleverly used reflection to identify these classes [?????].  \r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}